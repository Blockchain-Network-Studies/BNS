{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:22:50.108854Z",
          "iopub.status.busy": "2021-12-26T16:22:50.108151Z",
          "iopub.status.idle": "2021-12-26T16:22:50.135581Z",
          "shell.execute_reply": "2021-12-26T16:22:50.134724Z",
          "shell.execute_reply.started": "2021-12-26T16:22:50.108741Z"
        },
        "id": "fsMLxiZWIpfL"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNdHCMORIpfN"
      },
      "source": [
        "### 1. Token Transfer Data Querying"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0vcW78jIpfP"
      },
      "source": [
        "#### Aave Transfer data querying (from Google Big Query) using Kaggle's public dataset BigQuery integration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:23:23.715782Z",
          "iopub.status.busy": "2021-12-26T16:23:23.715483Z",
          "iopub.status.idle": "2021-12-26T16:23:24.347895Z",
          "shell.execute_reply": "2021-12-26T16:23:24.347110Z",
          "shell.execute_reply.started": "2021-12-26T16:23:23.715749Z"
        },
        "id": "LSGvWIRKIpfP"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import zipfile\n",
        "\n",
        "from tqdm import tqdm\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Create a \"Client\" object\n",
        "client = bigquery.Client()\n",
        "\n",
        "# Construct a reference to the \"crypto_ethereum\" dataset (https://www.kaggle.com/bigquery/ethereum-blockchain)\n",
        "dataset_ref = client.dataset(\"crypto_ethereum\", project=\"bigquery-public-data\")\n",
        "\n",
        "# API request - fetch the dataset\n",
        "dataset = client.get_dataset(dataset_ref)\n",
        "\n",
        "# List all the tables in the \"crypto_ethereum\" dataset\n",
        "tables = list(client.list_tables(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:23:24.349433Z",
          "iopub.status.busy": "2021-12-26T16:23:24.349223Z",
          "iopub.status.idle": "2021-12-26T16:23:24.354668Z",
          "shell.execute_reply": "2021-12-26T16:23:24.353907Z",
          "shell.execute_reply.started": "2021-12-26T16:23:24.349407Z"
        },
        "id": "VqyLQV6cIpfP"
      },
      "outputs": [],
      "source": [
        "def query_to_csv(sql, output_path): \n",
        "    df = client.query(sql).to_dataframe(progress_bar_type='tqdm_notebook')\n",
        "    df.to_csv(output_path, mode='a', index=False, header=not os.path.exists(output_path), compression='gzip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:23:24.994000Z",
          "iopub.status.busy": "2021-12-26T16:23:24.993190Z",
          "iopub.status.idle": "2021-12-26T16:25:47.152973Z",
          "shell.execute_reply": "2021-12-26T16:25:47.152270Z",
          "shell.execute_reply.started": "2021-12-26T16:23:24.993941Z"
        },
        "id": "WIBpyX95IpfQ"
      },
      "outputs": [],
      "source": [
        "sql = '''\n",
        "SELECT token_address, from_address, to_address,block_timestamp, cast(value AS NUMERIC) FROM \n",
        "`bigquery-public-data.crypto_ethereum.token_transfers` \n",
        "WHERE token_address = \"0x7fc66500c84a76ad7e9c93437bfc5ac33e2ddae9\"\n",
        "'''\n",
        "df = client.query(sql).to_dataframe(progress_bar_type='tqdm_notebook')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:25:47.154382Z",
          "iopub.status.busy": "2021-12-26T16:25:47.154189Z",
          "iopub.status.idle": "2021-12-26T16:26:03.764037Z",
          "shell.execute_reply": "2021-12-26T16:26:03.763133Z",
          "shell.execute_reply.started": "2021-12-26T16:25:47.154357Z"
        },
        "id": "pfPq9bSNIpfQ"
      },
      "outputs": [],
      "source": [
        "# data cleaning\n",
        "df.rename(columns={'f0_':'value'}, inplace = True)\n",
        "df = df.dropna()\n",
        "df['value'] = df['value'].apply(lambda x: float(x))\n",
        "df['timestamp'] = pd.to_datetime(df['block_timestamp'])\n",
        "df['timestamp'] = df['timestamp'].apply(lambda x: str(x)[:10])\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "\n",
        "df = df[df['timestamp']>'2020-10-09']\n",
        "df = df[df['timestamp']<'2021-10-10']\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi5nCaGhIpfR"
      },
      "source": [
        "#### Output Raw Token Transfer Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:26:03.765511Z",
          "iopub.status.busy": "2021-12-26T16:26:03.765285Z",
          "iopub.status.idle": "2021-12-26T16:26:34.071380Z",
          "shell.execute_reply": "2021-12-26T16:26:34.070171Z",
          "shell.execute_reply.started": "2021-12-26T16:26:03.765482Z"
        },
        "id": "scjdyhi2IpfR"
      },
      "outputs": [],
      "source": [
        "df.to_csv('Aave Raw Transfer Data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:26:34.074491Z",
          "iopub.status.busy": "2021-12-26T16:26:34.074163Z",
          "iopub.status.idle": "2021-12-26T16:26:34.111411Z",
          "shell.execute_reply": "2021-12-26T16:26:34.110543Z",
          "shell.execute_reply.started": "2021-12-26T16:26:34.074443Z"
        },
        "id": "a3eivZ7xIpfS"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns = ['token_address','block_timestamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:26:34.113252Z",
          "iopub.status.busy": "2021-12-26T16:26:34.112790Z",
          "iopub.status.idle": "2021-12-26T16:26:42.104768Z",
          "shell.execute_reply": "2021-12-26T16:26:42.104192Z",
          "shell.execute_reply.started": "2021-12-26T16:26:34.113219Z"
        },
        "id": "pa-LGbeyIpfS"
      },
      "outputs": [],
      "source": [
        "## add values between the 2 same addresses together\n",
        "df[['from_address', 'to_address']] = np.sort(df[['from_address', 'to_address']], axis=1)\n",
        "df= df.groupby(['timestamp','from_address','to_address']).agg(lambda x: sum(x)).reset_index()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:26:42.106382Z",
          "iopub.status.busy": "2021-12-26T16:26:42.105783Z",
          "iopub.status.idle": "2021-12-26T16:26:53.657782Z",
          "shell.execute_reply": "2021-12-26T16:26:53.656861Z",
          "shell.execute_reply.started": "2021-12-26T16:26:42.106333Z"
        },
        "id": "XQw4oS1RIpfS"
      },
      "outputs": [],
      "source": [
        "df.to_csv('AAVE transaction data_after preprocessing.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVS1YkBcIpfT"
      },
      "source": [
        "### 2. Network Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPYveF1_IpfT"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('AAVE transaction data_after preprocessing.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:26:53.659009Z",
          "iopub.status.busy": "2021-12-26T16:26:53.658815Z",
          "iopub.status.idle": "2021-12-26T16:26:53.952529Z",
          "shell.execute_reply": "2021-12-26T16:26:53.951723Z",
          "shell.execute_reply.started": "2021-12-26T16:26:53.658984Z"
        },
        "id": "hmLr1u4fIpfT"
      },
      "outputs": [],
      "source": [
        "df_time_partition= df.groupby(['timestamp'])['to_address'].agg(['nunique']).reset_index()\n",
        "df_time_partition = df_time_partition.drop(['nunique'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL6j8JhrIpfT"
      },
      "source": [
        "#### a. Number of daily edges and nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:27:29.681570Z",
          "iopub.status.busy": "2021-12-26T16:27:29.681248Z",
          "iopub.status.idle": "2021-12-26T16:27:36.912096Z",
          "shell.execute_reply": "2021-12-26T16:27:36.911353Z",
          "shell.execute_reply.started": "2021-12-26T16:27:29.681539Z"
        },
        "id": "ryTBlo2kIpfT"
      },
      "outputs": [],
      "source": [
        "# Daily Network Building\n",
        "import networkx as nx\n",
        "num_nodes = []\n",
        "num_edges = []\n",
        "for i in range(0,len(df_time_partition)):\n",
        "    \n",
        "    # Data Partition\n",
        "    df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    \n",
        "    # MultiDi Network Building (weighted-directed graph)\n",
        "    G = nx.from_pandas_edgelist(df_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    \n",
        "    # Calculation of Number of nodes, number of edges\n",
        "    nodes = G.number_of_nodes()\n",
        "    edges = G.number_of_edges()\n",
        "    num_nodes.append(nodes)\n",
        "    num_edges.append(edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:27:36.913989Z",
          "iopub.status.busy": "2021-12-26T16:27:36.913748Z",
          "iopub.status.idle": "2021-12-26T16:27:36.920720Z",
          "shell.execute_reply": "2021-12-26T16:27:36.919717Z",
          "shell.execute_reply.started": "2021-12-26T16:27:36.913959Z"
        },
        "id": "f9yw0WSXIpfU"
      },
      "outputs": [],
      "source": [
        "Network_Features={\"num_nodes\" : num_nodes,\"num_edges\" : num_edges}\n",
        "Network_Features=pd.DataFrame(Network_Features)\n",
        "Network_Features['time'] =  df_time_partition['timestamp']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjoI8XnQIpfU"
      },
      "source": [
        "#### b. Degree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:27:36.922420Z",
          "iopub.status.busy": "2021-12-26T16:27:36.922086Z",
          "iopub.status.idle": "2021-12-26T16:27:44.226791Z",
          "shell.execute_reply": "2021-12-26T16:27:44.225903Z",
          "shell.execute_reply.started": "2021-12-26T16:27:36.922387Z"
        },
        "id": "X5tpRkY6IpfU"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "Degreemean = []\n",
        "Degreestd = []\n",
        "for i in range(0,len(df_time_partition)):\n",
        "    \n",
        "    # Data Partition\n",
        "    df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    #df_1 = actsenrec.loc[actsenrec['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    \n",
        "    # MultiDi Network Building (weighted-directed graph)\n",
        "    G = nx.from_pandas_edgelist(df_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    \n",
        "    # Calculation of Degree_centrality, mean_value\n",
        "    degrees = G.degree()\n",
        "    degree = list(dict(G.degree()).values())\n",
        "    df_deg = {\"Degree\" : degree}\n",
        "    df_deg = pd.DataFrame(df_deg)\n",
        "    DC_mean = df_deg['Degree'].mean()\n",
        "    DC_std = df_deg['Degree'].std()\n",
        "    Degreemean.append(DC_mean)\n",
        "    Degreestd.append(DC_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:29:01.466109Z",
          "iopub.status.busy": "2021-12-26T16:29:01.465818Z",
          "iopub.status.idle": "2021-12-26T16:29:01.472911Z",
          "shell.execute_reply": "2021-12-26T16:29:01.471804Z",
          "shell.execute_reply.started": "2021-12-26T16:29:01.466072Z"
        },
        "id": "w3IEjPCdIpfU"
      },
      "outputs": [],
      "source": [
        "Network_Features['Degree mean']  = Degreemean\n",
        "Network_Features['Degree std']  = Degreestd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5z2qQpMIpfU"
      },
      "source": [
        "#### c. Top 10 addresses degree ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:29:12.054322Z",
          "iopub.status.busy": "2021-12-26T16:29:12.053846Z",
          "iopub.status.idle": "2021-12-26T16:29:22.523497Z",
          "shell.execute_reply": "2021-12-26T16:29:22.522327Z",
          "shell.execute_reply.started": "2021-12-26T16:29:12.054287Z"
        },
        "id": "6I3SHMq8IpfU"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "top10Degreemean = []\n",
        "top10Degreestd = []\n",
        "\n",
        "for i in range(0,len(df_time_partition)):\n",
        "\n",
        "    df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    sender_mdegree= df_1.groupby(['from_address'])['to_address'].count().reset_index()\n",
        "    receiver_mdegree = df_1.groupby(['to_address'])['from_address'].count().reset_index()\n",
        "    sender_mdegree = sender_mdegree.rename(columns={'to_address':'degree'})\n",
        "    sender_mdegree = sender_mdegree.rename(columns={'from_address':'address'})\n",
        "    receiver_mdegree = receiver_mdegree.rename(columns = {'from_address':'degree'})\n",
        "    receiver_mdegree = receiver_mdegree.rename(columns = {'to_address':'address'})\n",
        "\n",
        "    merge = pd.merge(sender_mdegree,receiver_mdegree,on=\"address\",how = \"outer\")\n",
        "    merge = merge.fillna(int(0))\n",
        "    merge['degree'] = merge['degree_x']+merge['degree_y']\n",
        "\n",
        "    merge.sort_values(by=['degree'], ascending=False, inplace=True)\n",
        "    merge = merge.reset_index()\n",
        "    top5degree = merge['address'][0:10].tolist()\n",
        "\n",
        "    sen_top =  df_1[df_1['from_address'].isin(top5degree)]\n",
        "    rec_top= df_1[df_1['to_address'].isin(top5degree)]\n",
        "\n",
        "    topaddress = pd.concat([sen_top,rec_top]).drop_duplicates()\n",
        "\n",
        "    G = nx.from_pandas_edgelist(topaddress, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    # Calculation of absolute degree\n",
        "    degree = []\n",
        "    for j in range (0,10):\n",
        "        degrees = G.degree(top5degree[j])\n",
        "        degree.append(degrees)\n",
        "    df_deg = {\"Degree\" : degree}\n",
        "    df_deg = pd.DataFrame(df_deg)\n",
        "    deg_mean = df_deg['Degree'].mean()\n",
        "    deg_std = df_deg['Degree'].std()\n",
        "    top10Degreemean.append(deg_mean)\n",
        "    top10Degreestd.append(deg_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:29:22.525804Z",
          "iopub.status.busy": "2021-12-26T16:29:22.525429Z",
          "iopub.status.idle": "2021-12-26T16:29:22.532149Z",
          "shell.execute_reply": "2021-12-26T16:29:22.531357Z",
          "shell.execute_reply.started": "2021-12-26T16:29:22.525760Z"
        },
        "id": "BtJpyz2HIpfV"
      },
      "outputs": [],
      "source": [
        "Network_Features['Top10Degree mean']  = top10Degreemean\n",
        "Network_Features['Top10Degree std']  = top10Degreestd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:29:22.534327Z",
          "iopub.status.busy": "2021-12-26T16:29:22.533566Z",
          "iopub.status.idle": "2021-12-26T16:29:22.547309Z",
          "shell.execute_reply": "2021-12-26T16:29:22.546475Z",
          "shell.execute_reply.started": "2021-12-26T16:29:22.534282Z"
        },
        "id": "HV7UGYqEIpfV"
      },
      "outputs": [],
      "source": [
        "Network_Features['Top10 Degree mean ratio']  = Network_Features['Top10Degree mean']/Network_Features['Degree mean']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh-kx2ekIpfV"
      },
      "source": [
        "#### d. Degree centrality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:29:30.214901Z",
          "iopub.status.busy": "2021-12-26T16:29:30.214005Z",
          "iopub.status.idle": "2021-12-26T16:29:37.709810Z",
          "shell.execute_reply": "2021-12-26T16:29:37.709093Z",
          "shell.execute_reply.started": "2021-12-26T16:29:30.214854Z"
        },
        "id": "rOhFTPK1IpfV"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "DCmean = []\n",
        "DCstd = []\n",
        "for i in range(0,len(df_time_partition)):\n",
        "    \n",
        "    # Data Partition\n",
        "    df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    #df_1 = actsenrec.loc[actsenrec['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    \n",
        "    # MultiDi Network Building (weighted-directed graph)\n",
        "    G = nx.from_pandas_edgelist(df_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    \n",
        "    # Calculation of Degree_centrality, mean_value\n",
        "    deg_cen = nx.degree_centrality(G)\n",
        "    df_deg = pd.DataFrame.from_dict(deg_cen, orient='index', columns=['Degree_Centrality'])\n",
        "    DC_mean = df_deg['Degree_Centrality'].mean()\n",
        "    DC_std = df_deg['Degree_Centrality'].std()\n",
        "    DCmean.append(DC_mean)\n",
        "    DCstd.append(DC_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w102T9BxIpfV"
      },
      "source": [
        "#### e. Clustering coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T17:40:57.983372Z",
          "iopub.status.busy": "2021-12-26T17:40:57.982912Z",
          "iopub.status.idle": "2021-12-26T17:41:18.074423Z",
          "shell.execute_reply": "2021-12-26T17:41:18.073604Z",
          "shell.execute_reply.started": "2021-12-26T17:40:57.983330Z"
        },
        "id": "78EJXWV_IpfV"
      },
      "outputs": [],
      "source": [
        "clustermean = []\n",
        "clusterstd = []\n",
        "for i in range(0,len(df_time_partition)):\n",
        "    \n",
        "    # Data Partition\n",
        "    df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    #df_1 = actsenrec.loc[actsenrec['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    \n",
        "    # Unweighted-Directed Network Building (weighted-directed graph)\n",
        "    G = nx.from_pandas_edgelist(df_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    \n",
        "    # Calculation of Clustering_Coefficient, mean_value, std\n",
        "    clustering = nx.clustering(G)\n",
        "    df_cluster = pd.DataFrame.from_dict(clustering, orient='index', columns=['Clustering_Coefficient'])\n",
        "    cluster_mean = df_cluster['Clustering_Coefficient'].mean()\n",
        "    cluster_std = df_cluster['Clustering_Coefficient'].std()\n",
        "    clustermean.append(cluster_mean)\n",
        "    clusterstd.append(cluster_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKqbkBLMIpfV"
      },
      "source": [
        "#### f. Modularity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:57:21.446764Z",
          "iopub.status.busy": "2021-12-26T16:57:21.446431Z",
          "iopub.status.idle": "2021-12-26T16:58:53.387942Z",
          "shell.execute_reply": "2021-12-26T16:58:53.387089Z",
          "shell.execute_reply.started": "2021-12-26T16:57:21.446720Z"
        },
        "id": "eR5yIcHzIpfV"
      },
      "outputs": [],
      "source": [
        "import community\n",
        "mod_list = []\n",
        "for i in range(0,len(df_time_partition)):\n",
        "    \n",
        "    # Data Partition\n",
        "    df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    #df_1 = actsenrec.loc[actsenrec['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    \n",
        "    # unweighted-undirected Network Building (weighted-directed graph)\n",
        "    G = nx.from_pandas_edgelist(df_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    \n",
        "    # Calculation of modularity\n",
        "    part = community.best_partition(G)\n",
        "    mod = community.modularity(part,G)\n",
        "    mod_list.append(mod)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVs3o1oKIpfV"
      },
      "source": [
        "#### g. Transitivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:58:53.389388Z",
          "iopub.status.busy": "2021-12-26T16:58:53.389174Z",
          "iopub.status.idle": "2021-12-26T16:59:12.849768Z",
          "shell.execute_reply": "2021-12-26T16:59:12.848911Z",
          "shell.execute_reply.started": "2021-12-26T16:58:53.389363Z"
        },
        "id": "jQSJZPQ6IpfV"
      },
      "outputs": [],
      "source": [
        "tran_list = []\n",
        "for i in range(0,len(df_time_partition)):\n",
        "    \n",
        "    # Data Partition\n",
        "    df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    #df_1 = actsenrec.loc[actsenrec['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    \n",
        "    # Unweighted-undirected Network Building (weighted-directed graph)\n",
        "    G = nx.from_pandas_edgelist(df_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    \n",
        "    # Calculation of transitivity, \n",
        "    tran = nx.transitivity(G)\n",
        "    tran_list.append(tran)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4Lp4uKfIpfV"
      },
      "source": [
        "#### h. Eigenvector Centrality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T16:59:12.853053Z",
          "iopub.status.busy": "2021-12-26T16:59:12.852712Z",
          "iopub.status.idle": "2021-12-26T17:01:50.488860Z",
          "shell.execute_reply": "2021-12-26T17:01:50.487942Z",
          "shell.execute_reply.started": "2021-12-26T16:59:12.853006Z"
        },
        "id": "wFQnKG87IpfV"
      },
      "outputs": [],
      "source": [
        "eigmean = []\n",
        "eigstd = []\n",
        "for i in range(0,len(df_time_partition)):\n",
        "    \n",
        "    # Data Partition\n",
        "    df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    #df_1 = actsenrec.loc[actsenrec['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    \n",
        "    # MultiDi Network Building (weighted-directed graph)\n",
        "    G = nx.from_pandas_edgelist(df_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    \n",
        "    # Calculation of Closeness_centrality, mean_value\n",
        "    eig_cen = nx.eigenvector_centrality(G, max_iter=20000)\n",
        "    df_eig = pd.DataFrame.from_dict(eig_cen, orient='index', columns=['eigenvector_centrality'])\n",
        "    eig_mean = df_eig['eigenvector_centrality'].mean()\n",
        "    eig_std = df_eig['eigenvector_centrality'].std()\n",
        "    eigmean.append(eig_mean)\n",
        "    eigstd.append(eig_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gGnpVZLIpfW"
      },
      "source": [
        "#### i. Closeness Centrality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T17:01:50.490637Z",
          "iopub.status.busy": "2021-12-26T17:01:50.490392Z",
          "iopub.status.idle": "2021-12-26T17:29:15.708605Z",
          "shell.execute_reply": "2021-12-26T17:29:15.707713Z",
          "shell.execute_reply.started": "2021-12-26T17:01:50.490609Z"
        },
        "id": "2EKPU6aNIpfW"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "CCmean = []\n",
        "CCstd = []\n",
        "for i in range(0,len(df_time_partition)):\n",
        "    \n",
        "    # Data Partition\n",
        "    df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    \n",
        "    # MultiDi Network Building (weighted-directed graph)\n",
        "    G = nx.from_pandas_edgelist(df_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    \n",
        "    # Calculation of Closeness_centrality, mean_value\n",
        "    close_cen = nx.closeness_centrality(G)\n",
        "    df_close = pd.DataFrame.from_dict(close_cen, orient='index', columns=['Closeness_Centrality'])\n",
        "    CC_mean = df_close['Closeness_Centrality'].mean()\n",
        "    CC_std = df_close['Closeness_Centrality'].std()\n",
        "    CCmean.append(CC_mean)\n",
        "    CCstd.append(CC_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSHSWZfLIpfW"
      },
      "source": [
        "#### j. Number of components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T17:29:15.710201Z",
          "iopub.status.busy": "2021-12-26T17:29:15.709941Z",
          "iopub.status.idle": "2021-12-26T17:29:23.559579Z",
          "shell.execute_reply": "2021-12-26T17:29:23.558943Z",
          "shell.execute_reply.started": "2021-12-26T17:29:15.710170Z"
        },
        "id": "r7s1tA49IpfW"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "components_cnt = []\n",
        "for i in range(0,len(df_time_partition)):\n",
        "    df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    G = nx.from_pandas_edgelist(df_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    com_cnt = nx.number_connected_components(G)\n",
        "    components_cnt.append(com_cnt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-aRMTS6IpfW"
      },
      "source": [
        "#### k. Size of gaint component / num of nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "644R5iamIpfW"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "giant_com_ratio = []\n",
        "for i in range(0,len(df_time_partition)):\n",
        "    df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    G = nx.from_pandas_edgelist(df_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "# G = nx.Graph()\n",
        "    Gcc = sorted(nx.connected_components(G), key=len, reverse=True)\n",
        "    G0 = G.subgraph(Gcc[0])\n",
        "#com_cnt = nx.number_connected_components(G)\n",
        "#components_cnt.append(com_cnt)\n",
        "    nodes = G0.number_of_nodes()\n",
        "    nodes_whole = G.number_of_nodes()\n",
        "    ratio = nodes/nodes_whole\n",
        "    giant_com_ratio.append(ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T17:41:18.076247Z",
          "iopub.status.busy": "2021-12-26T17:41:18.076012Z",
          "iopub.status.idle": "2021-12-26T17:41:18.089495Z",
          "shell.execute_reply": "2021-12-26T17:41:18.088394Z",
          "shell.execute_reply.started": "2021-12-26T17:41:18.076219Z"
        },
        "id": "MpbeIr-nIpfW"
      },
      "outputs": [],
      "source": [
        "Network_Features['DCmean']=DCmean\n",
        "Network_Features['DCstd']=DCstd\n",
        "Network_Features['clustermean']=clustermean\n",
        "Network_Features['clusterstd']=clusterstd\n",
        "Network_Features['modularity']=mod_list\n",
        "Network_Features['transitivity']=tran_list\n",
        "Network_Features['eig_mean']=eigmean\n",
        "Network_Features['eig_std']=eigstd\n",
        "Network_Features['closenessmean']=CCmean\n",
        "Network_Features['closenessstd']=CCstd\n",
        "Network_Features['Components_cnt']=components_cnt\n",
        "Network_Features['giant_com_ratio']=giant_com_ratio\n",
        "\n",
        "Network_Features['token'] =  'AAVE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T17:41:36.592295Z",
          "iopub.status.busy": "2021-12-26T17:41:36.591987Z",
          "iopub.status.idle": "2021-12-26T17:41:36.618459Z",
          "shell.execute_reply": "2021-12-26T17:41:36.617629Z",
          "shell.execute_reply.started": "2021-12-26T17:41:36.592264Z"
        },
        "id": "duZZiVUIIpfW"
      },
      "outputs": [],
      "source": [
        "Network_Features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnOyamCoIpfW"
      },
      "source": [
        "#### Output network features dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-26T17:43:33.660306Z",
          "iopub.status.busy": "2021-12-26T17:43:33.659648Z",
          "iopub.status.idle": "2021-12-26T17:43:33.687116Z",
          "shell.execute_reply": "2021-12-26T17:43:33.685962Z",
          "shell.execute_reply.started": "2021-12-26T17:43:33.660253Z"
        },
        "id": "VokfXU1SIpfW"
      },
      "outputs": [],
      "source": [
        "Network_Features.to_csv('AAVE_Network_Features.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjE3zDHHIpfW"
      },
      "source": [
        "### 3. Core-periphery Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mkXl1JqIpfW"
      },
      "outputs": [],
      "source": [
        "pip install cpnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBUzdD2BIpfW"
      },
      "outputs": [],
      "source": [
        "import cpnet\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRnyMtp4IpfW"
      },
      "source": [
        "#### Basic structure significance test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p81XWaKAIpfX"
      },
      "outputs": [],
      "source": [
        "df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][135]]\n",
        "G = nx.from_pandas_edgelist(df_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    \n",
        "\n",
        "alg = cpnet.BE()\n",
        "alg.detect(G)\n",
        "c = alg.get_pair_id()\n",
        "x = alg.get_coreness()  # Get the coreness of nodes\n",
        "\n",
        "##coreness = pd.DataFrame.from_dict(x, orient='index', columns=['Coreness'])\n",
        "##corenessmean = coreness['Coreness'].mean()\n",
        "#corenessmean\n",
        "\n",
        "sig_c, sig_x, significant, p_values = cpnet.qstest(\n",
        "    c, x, G, alg, significance_level=0.05, num_of_rand_net=100, num_of_thread=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjL_UL8bIpfX"
      },
      "outputs": [],
      "source": [
        "print(significant)\n",
        "print(p_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zppWlLPsIpfX"
      },
      "source": [
        "#### Continuous structure significance test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSKxCjhNIpfX",
        "outputId": "b2cb6510-aa87-479a-f2d6-aba378bc9ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cea17a7d8ffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mdf_time_partition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas_edgelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_address'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'to_address'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Calculation of mean&std of coreness (continuous structure)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0malg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcpnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMINRES\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][90]]\n",
        "G = nx.from_pandas_edgelist(df_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    \n",
        "    # Calculation of mean&std of coreness (continuous structure)\n",
        "alg = cpnet.MINRES()\n",
        "alg.detect(G)\n",
        "x = alg.get_coreness() \n",
        "    \n",
        "#coreness = pd.DataFrame.from_dict(x, orient='index', columns=['Coreness'])\n",
        "#corenessmean = coreness['Coreness'].mean()\n",
        "#corenessstd = coreness['Coreness'].std()\n",
        "#print ('mean', corenessmean)\n",
        "#print ('std', corenessstd)\n",
        "\n",
        "sig_c, sig_x, significant, p_values = cpnet.qstest(\n",
        "    c, x, G, alg, significance_level=0.05, num_of_rand_net=100, num_of_thread=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJmOQcYAIpfX"
      },
      "outputs": [],
      "source": [
        "print(significant)\n",
        "print(p_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkrCjsdXIpfX"
      },
      "source": [
        "#### Core-periphery Network Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVh-H5ooIpfX"
      },
      "outputs": [],
      "source": [
        "pos = nx.spiral_layout(G,scale = 3)\n",
        "fig = plt.figure(figsize=(14, 12))\n",
        "ax = plt.gca()\n",
        "draw_nodes_kwd = {\"node_size\": 80, \"linewidths\": 0.8}\n",
        "ax, pos = cpnet.draw(G, sig_c, sig_x, ax,draw_nodes_kwd=draw_nodes_kwd,\n",
        "                     layout_kwd = {\"verbose\":True, \"iterations\":500})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1baJllaIpfX"
      },
      "source": [
        "#### Output core addresses and corresponding date counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-qDE6AvIpfX"
      },
      "outputs": [],
      "source": [
        "core_address = []\n",
        "a = 0\n",
        "for i in range(0,len(df_time_partition)):\n",
        "    df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    G = nx.from_pandas_edgelist(df_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    alg = cpnet.BE()\n",
        "    alg.detect(G)\n",
        "    c = alg.get_pair_id()\n",
        "    x = alg.get_coreness()\n",
        "\n",
        "    coredf = pd.DataFrame.from_dict(x, orient='index',columns=['coreness'])\n",
        "    core = coredf[coredf['coreness']==1].index.tolist()\n",
        "    core_address.extend(core)\n",
        "    a+=1\n",
        "    print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmDY2X9BIpfX"
      },
      "outputs": [],
      "source": [
        "cores = pd.DataFrame(core_address)\n",
        "core_cnt = cores[0].value_counts(ascending=False).reset_index()\n",
        "core_cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73hFD8vbIpfX"
      },
      "outputs": [],
      "source": [
        "core_cnt.to_csv('core_date_cnt.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzKls4YhIpfX"
      },
      "source": [
        "#### Number of core members each day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3iyUqzuIpfX"
      },
      "outputs": [],
      "source": [
        "core_cnt = []\n",
        "for i in range(0,len(df_time_partition)):\n",
        "    df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][i]]\n",
        "    G = nx.from_pandas_edgelist(df_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    alg = cpnet.BE()\n",
        "    alg.detect(G)\n",
        "    c = alg.get_pair_id()\n",
        "    x = alg.get_coreness()\n",
        "\n",
        "    coredf = pd.DataFrame.from_dict(x, orient='index',columns=['coreness'])\n",
        "    core = coredf[coredf['coreness']==1].index.tolist()\n",
        "    cnt = len(core)\n",
        "    core_cnt.append(cnt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m40tWbSXIpfX"
      },
      "source": [
        "#### Average number of neighbors of cores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lBtrAmtIpfY"
      },
      "outputs": [],
      "source": [
        "from numpy import *\n",
        "avg_core_neighbor = []\n",
        "\n",
        "for i in range(0,len(df_time_partition)):\n",
        "    df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][0]]\n",
        "    G = nx.from_pandas_edgelist(df_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    alg = cpnet.BE()\n",
        "    alg.detect(G)\n",
        "    c = alg.get_pair_id()\n",
        "    x = alg.get_coreness()\n",
        "\n",
        "    coredf = pd.DataFrame.from_dict(x, orient='index',columns=['coreness'])\n",
        "    core = coredf[coredf['coreness']==1].index.tolist()\n",
        "\n",
        "    neighbor_cnt = []\n",
        "    for i in range (0,len(core)):\n",
        "        neighbor = G.degree(core[i])\n",
        "        neighbor_cnt.append(neighbor)\n",
        "    \n",
        "    neighbor_cnt_mean = mean(neighbor_cnt)\n",
        "    avg_core_neighbor.append(neighbor_cnt_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT2kdfvFIpfY"
      },
      "source": [
        "#### Update Network Features dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmsS6gUyIpfY"
      },
      "outputs": [],
      "source": [
        "Network_Features = pd.read_csv('AAVE_Network_Features.csv')\n",
        "Network_Features['core_cnt']=core_cnt\n",
        "Network_Features['core_ratio']=Network_Features['core_cnt']/Network_Features['num_nodes']\n",
        "Network_Features['avg_core_neighbor']=avg_core_neighbor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K12q4l7bIpfY"
      },
      "outputs": [],
      "source": [
        "#Deal with the outlier\n",
        "# average of past 5 days\n",
        "Network_Features['core_cnt'][230]=2\n",
        "Network_Features['core_ratio'][230] = 2/df_AAVE['num_nodes'][230]\n",
        "Network_Features['avg_core_neighbor'][230] = 217.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcpinjrwIpfY"
      },
      "outputs": [],
      "source": [
        "Network_Features.to_csv('AAVE_Network_Features.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcekM-eKIpfY"
      },
      "source": [
        "### 4. Impulse Response Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHp49FE-IpfY"
      },
      "source": [
        "#### Remove Top 5% addresses in both degree and transaction value between 11.10 and 12.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRgubjT-IpfY"
      },
      "outputs": [],
      "source": [
        "firstmonth  = df_time_partition.iloc[31:62]\n",
        "secondmonth = df_time_partition.iloc[62:94]\n",
        "secondmonth = secondmonth.reset_index()\n",
        "\n",
        "df_1month = df[df['timestamp'].isin(firstmonth['timestamp'])]\n",
        "df_2month = df[df['timestamp'].isin(secondmonth['timestamp'])]\n",
        "\n",
        "sender_mdegree= df_1month.groupby(['from_address'])['to_address'].count().reset_index()\n",
        "receiver_mdegree = df_1month.groupby(['to_address'])['from_address'].count().reset_index()\n",
        "sender_mdegree = sender_mdegree.rename(columns={'to_address':'degree'})\n",
        "sender_mdegree = sender_mdegree.rename(columns={'from_address':'address'})\n",
        "receiver_mdegree = receiver_mdegree.rename(columns = {'from_address':'degree'})\n",
        "receiver_mdegree = receiver_mdegree.rename(columns = {'to_address':'address'})\n",
        "\n",
        "merge = pd.merge(sender_mdegree,receiver_mdegree,on=\"address\",how = \"outer\")\n",
        "merge = merge.fillna(int(0))\n",
        "merge['degree'] = merge['degree_x']+merge['degree_y']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Rl1w1eiIpfY"
      },
      "outputs": [],
      "source": [
        "df_sender_txval_tot = df_1month.groupby(['from_address'])['value'].sum().reset_index()\n",
        "df_receiver_txval_tot = df_1month.groupby(['to_address'])['value'].sum().reset_index()\n",
        "df_sender_txval_tot = df_sender_txval_tot.rename(columns={'from_address':'address'})\n",
        "df_receiver_txval_tot = df_receiver_txval_tot.rename(columns={'to_address':'address'})\n",
        "\n",
        "merge_tx = pd.merge(df_sender_txval_tot,df_receiver_txval_tot,on=\"address\",how = \"outer\")\n",
        "merge_tx = merge_tx.fillna(int(0))\n",
        "merge_tx['value'] = merge_tx['value_x']+merge_tx['value_y']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-ZTKdOoIpfY"
      },
      "outputs": [],
      "source": [
        "top5perct_rdegree = merge['degree'].quantile(0.95)\n",
        "top5_address_degree = merge[merge['degree']>=top5perct_rdegree]\n",
        "top5perct_tx = merge_tx['value'].quantile(0.95)\n",
        "top5_address_tx = merge_tx[merge_tx['value']>=top5perct_tx]\n",
        "\n",
        "top5_address = pd.merge(top5_address_degree,top5_address_tx,how='inner',on=\"address\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMC9hzW3IpfY"
      },
      "outputs": [],
      "source": [
        "sender_remove = df_2month[~df_2month['from_address'].isin(top5_address['address'])]\n",
        "allremove = sender_remove[~sender_remove['to_address'].isin(top5_address['address'])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW53HiqwIpfY"
      },
      "source": [
        "#### Randomly remove 5% addresses in the first month 11.10-12.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NnQMIGqIpfY"
      },
      "outputs": [],
      "source": [
        "import random\n",
        " \n",
        "address_remove = merge.sample(n=int(0.05*len(merge)), replace=False, axis=0)\n",
        "sen_ar = df_2month[~df_2month['from_address'].isin(address_remove['address'])]\n",
        "senrec_ar= sen_ar[~sen_ar['to_address'].isin(address_remove['address'])]\n",
        "senrec_ar = senrec_ar.reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ02QgyCIpfY"
      },
      "source": [
        "#### Remove the core addresses on 12.11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZclkJIilIpfY"
      },
      "outputs": [],
      "source": [
        "pip install cpnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QD5fypgIpfY"
      },
      "outputs": [],
      "source": [
        "import cpnet\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwqWBo5iIpfY"
      },
      "outputs": [],
      "source": [
        "df_1 = df.loc[df['timestamp']==df_time_partition['timestamp'][2]]\n",
        "G = nx.from_pandas_edgelist(df_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "alg = cpnet.BE()\n",
        "alg.detect(G)\n",
        "c = alg.get_pair_id()\n",
        "x = alg.get_coreness()\n",
        "\n",
        "coredf = pd.DataFrame.from_dict(x, orient='index',columns=['coreness'])\n",
        "core = coredf[coredf['coreness']==1].index.tolist()\n",
        "core\n",
        "\n",
        "sen_periphery =  df_2month[~df_2month['from_address'].isin(core)]\n",
        "senrec_periphery= sen_periphery[~sen_periphery['to_address'].isin(core)]\n",
        "senrec_periphery = senrec_periphery.reset_index()\n",
        "senrec_periphery"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Notebook 1_ network-core-periphery-analysis.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}